{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabor ML - Problem 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample data based on HW problem\n",
    "def create_sample_data(n, d):\n",
    "\n",
    "    #covariance matrix\n",
    "    cov = np.identity(d)    \n",
    "    for i in range(d):\n",
    "        cov[i,i] = 1/(i+1)\n",
    "\n",
    "    #x sample data\n",
    "    x = np.random.multivariate_normal(np.zeros(d), cov, n)\n",
    "\n",
    "    #y sample data\n",
    "    y = np.zeros(n)\n",
    "    e = np.random.normal(0, 1, n)\n",
    "    for i in range(n):\n",
    "        y[i] = sum(x[i]) + e[i]\n",
    "    return x, y\n",
    "\n",
    "#OLS algorithm\n",
    "def run_algorithm_OLS(x, y, n, d):\n",
    "\n",
    "    #OLS\n",
    "    hold_matrix = np.zeros((d,d))\n",
    "    for i in range(n):\n",
    "        maxtrix_add = np.outer(x[i], x[i].T)\n",
    "        hold_matrix = np.add(hold_matrix, maxtrix_add)\n",
    "    hold_matrix = np.multiply(1/n, hold_matrix)\n",
    "    hold_matrix = np.linalg.inv(hold_matrix)\n",
    "\n",
    "    hold_vec = np.zeros(d)\n",
    "    for i in range(n):\n",
    "        add_vec = np.multiply(x[i], y[i])\n",
    "        hold_vec = np.add(hold_vec, add_vec)\n",
    "    hold_vec = np.multiply(1/n, hold_vec)\n",
    "\n",
    "    w = np.dot(hold_matrix, hold_vec)\n",
    "    return w\n",
    "\n",
    "#function to create a learning rate list\n",
    "def learning_rate(method_learning_rate, n):\n",
    "    #create a list of what the learning rate will be at step t\n",
    "    if method_learning_rate == \"static\":\n",
    "        learning_rate_list = [.1 for i in range(n)]\n",
    "    else:\n",
    "        learning_rate_list = [1/np.sqrt(i+1) for i in range(n)]\n",
    "    return learning_rate_list\n",
    "\n",
    "#function that calculates the average of parameters\n",
    "def average_w(w, n, d):\n",
    "    #calculate average of parameters\n",
    "    avg_w = np.zeros(d)\n",
    "    for t in range(n):\n",
    "        avg_w = np.add(avg_w, w[t])\n",
    "    avg_w = np.multiply(1/n, avg_w)\n",
    "    return avg_w\n",
    "\n",
    "#Gradient Descent\n",
    "def run_algorithm_GD(x, y, method_learning_rate, n, d):\n",
    "\n",
    "    #create a learning rate list based on method\n",
    "    learning_rate_list = learning_rate(method_learning_rate, n)\n",
    "\n",
    "    #create a matrix of parameters at each step\n",
    "    w = np.zeros((n,d))\n",
    "    #with an initial vector\n",
    "    w0 = np.zeros(d)\n",
    "\n",
    "    #follow details from homework\n",
    "    for t in range(n):\n",
    "        hold_vector_add = np.zeros(d)\n",
    "        if t == 0:\n",
    "            for i in range(n):\n",
    "                hold1 = np.multiply(np.dot(w0.T,x[i]),x[i])\n",
    "                hold2 = np.multiply(x[i], y[i])\n",
    "                hold3 = np.subtract(hold1, hold2)\n",
    "                hold_vector_add = np.add(hold_vector_add, hold3)\n",
    "            hold_vector_add = np.multiply(learning_rate_list[t],hold_vector_add)\n",
    "            hold_vector_add = np.multiply(2/n,hold_vector_add)\n",
    "            w[t] = np.subtract(w0, hold_vector_add)\n",
    "        else:\n",
    "            for i in range(n):\n",
    "                hold1 = np.multiply(np.dot(w[t-1].T,x[i]),x[i])\n",
    "                hold2 = np.multiply(x[i], y[i])\n",
    "                hold3 = np.subtract(hold1, hold2)\n",
    "                hold_vector_add = np.add(hold_vector_add, hold3)\n",
    "            hold_vector_add = np.multiply(learning_rate_list[t],hold_vector_add)\n",
    "            hold_vector_add = np.multiply(2/n,hold_vector_add)\n",
    "            w[t] = np.subtract(w[t-1], hold_vector_add)\n",
    "\n",
    "    avg_w = average_w(w, n, d)\n",
    "    return avg_w\n",
    "\n",
    "#Stochastic Gradient Descent\n",
    "def run_algorithm_SGD(x, y, method_learning_rate, n, d):\n",
    "\n",
    "    #create a learning rate list based on method\n",
    "    learning_rate_list = learning_rate(method_learning_rate)\n",
    "    \n",
    "    w = np.zeros((n,d))\n",
    "    w0 = np.zeros(d)\n",
    "\n",
    "    #follow details from homework\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            hold1 = np.multiply(np.dot(w0.T,x[t]),x[t])\n",
    "            hold2 = np.multiply(x[t], y[t])\n",
    "            hold_vec = np.subtract(hold1, hold2)\n",
    "            hold_vec = np.multiply(2,hold_vec)\n",
    "            hold_vec = np.multiply(learning_rate_list[t],hold_vec)\n",
    "            w[t] = np.subtract(w0, hold_vec)\n",
    "        else:\n",
    "            hold_vec = np.subtract(np.multiply(np.dot(w[t-1].T,x[t]),x[t]), np.multiply(x[t], y[t]))\n",
    "            hold_vec = np.multiply(2,hold_vec)\n",
    "            hold_vec = np.multiply(learning_rate_list[t],hold_vec)\n",
    "            w[t] = np.subtract(w[t-1], hold_vec)\n",
    "\n",
    "    avg_w = average_w(w, n, d)\n",
    "    return avg_w\n",
    "\n",
    "#calculate mean square error\n",
    "def mse_calc(x, y, w, n):\n",
    "    mse = 0\n",
    "    for i in range(n):\n",
    "        mse += np.square(np.dot(w.T,x[i])-y[i])\n",
    "    mse = mse/n\n",
    "    return mse\n",
    "\n",
    "#put the way I run everything into a function\n",
    "def calc_method_runs(num_iterations, iter_num, n_values, d_values, type_method, method_learning_rate):\n",
    "    track_results = pd.DataFrame()\n",
    "    while iter_num < num_iterations:\n",
    "        print(iter_num)\n",
    "        for n in n_values:\n",
    "            for d in d_values:\n",
    "                train_x, train_y = create_sample_data(n, d)\n",
    "                test_x, test_y = create_sample_data(n, d)\n",
    "                for method in type_method:\n",
    "                    start = time.time()\n",
    "                    if method == 'OLS':\n",
    "                        w = run_algorithm_OLS(train_x, train_y)\n",
    "                    elif method == 'GD':\n",
    "                        w = run_algorithm_GD(train_x, train_y, method_learning_rate)\n",
    "                    else:\n",
    "                        w = run_algorithm_SGD(train_x, train_y, method_learning_rate)\n",
    "                    end = time.time()\n",
    "                    train_mse = mse_calc(train_x, train_y, w)\n",
    "                    test_mse = mse_calc(test_x, test_y, w)\n",
    "                    run_time = (end - start)\n",
    "                    line_ = pd.DataFrame([[method, n, d, run_time, train_mse, test_mse]], columns = ['method','n_value','d_value','run_time','train_mse','test_mse'])\n",
    "                    track_results = pd.concat([track_results, line_], ignore_index = True)\n",
    "                    track_results.reset_index(drop = True, inplace = True)\n",
    "        iter_num += 1\n",
    "    return track_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for functions\n",
    "type_method = ['OLS','GD','SGD']\n",
    "n_values = [25, 50, 100, 250, 500]\n",
    "d_values = [5, 10, 25, 50, 100, 150]\n",
    "\n",
    "#average over the below iterations\n",
    "num_iterations = 10\n",
    "iter_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#performance when learning rate is static.\n",
    "method_learning_rate = \"static\"\n",
    "static_run = calc_method_runs(num_iterations, iter_num, n_values, d_values, type_method, method_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance when learning rate is dynamic.\n",
    "method_learning_rate = \"dynamic\"\n",
    "dynamic_run = calc_method_runs(num_iterations, iter_num, n_values, d_values, type_method, method_learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
